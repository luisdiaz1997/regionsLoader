{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b49fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cooler\n",
    "import bioframe as bf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import bbi\n",
    "from matplotlib import gridspec\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import regionsLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ee40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_path = '/home/users/luisfcd/data/regions/regions_10kb.tsv'\n",
    "cool_path = '/home/users/luisfcd/data/Hi-C/GM12878/4DNFIXP4QG5B.mcool'\n",
    "chip_path = '/home/users/luisfcd/data/CHIP/GM12878/'\n",
    "regionsize = 4000000\n",
    "resolution=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36de419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H3K27ac': '/home/users/luisfcd/data/CHIP/GM12878/H3K27ac/ENCFF469WVA.bigWig',\n",
       " 'H3K27me3': '/home/users/luisfcd/data/CHIP/GM12878/H3K27me3/ENCFF919DOR.bigWig',\n",
       " 'H3K9me3': '/home/users/luisfcd/data/CHIP/GM12878/H3K9me3/ENCFF683HCZ.bigWig'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigwig_dict = {}\n",
    "for path in glob(chip_path+'**/*.bigWig', recursive=True):\n",
    "    bigwig_dict[path.split('/')[-2]]=path\n",
    "\n",
    "bigwig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83011a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_array = np.squeeze(pd.read_csv(regions_path, header=None).values)\n",
    "regions_df = bf.from_any(list(regions_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f09d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_regions(regions_df, regionsize, step=10000):\n",
    "    mask = (regions_df.end - regions_df.start) > regionsize\n",
    "    all_regions = []\n",
    "    for i, row in regions_df[mask].iterrows():\n",
    "        for k in range(0, (row.end - row.start)-regionsize+1, step):\n",
    "            region = bf.to_ucsc_string((row.chrom, row.start+k, row.start+k+regionsize))\n",
    "            all_regions.append(region)\n",
    "    \n",
    "    return bf.from_any(all_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05edd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regions_df = get_all_regions(regions_df, regionsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f401e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2791250</td>\n",
       "      <td>6791250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2801250</td>\n",
       "      <td>6801250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chr1</td>\n",
       "      <td>2881250</td>\n",
       "      <td>6881250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom    start      end\n",
       "1   chr1  2791250  6791250\n",
       "2   chr1  2801250  6801250\n",
       "10  chr1  2881250  6881250"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_regions_df.iloc[[1,2, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb1c688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_regions_df = bf.select(all_regions_df, 'chr5').sample(frac=1, random_state=28) #select a chromosome and shuffle it\n",
    "train_regions_df = target_regions_df.iloc[:int(len(target_regions_df)*0.8)].reset_index(drop=True)\n",
    "test_regions_df = target_regions_df.iloc[int(len(target_regions_df)*0.8):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf3c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = all_regions_df.chrom.unique()[1:4]\n",
    "for chrom in chroms:\n",
    "    target_regions_df = bf.select(all_regions_df, chrom).sample(frac=1, random_state=28)\n",
    "    train_regions_df_temp = target_regions_df.iloc[:int(len(target_regions_df)*0.8)].reset_index(drop=True)\n",
    "    train_regions_df = pd.concat((train_regions_df, train_regions_df_temp), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f172a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_set(hic_generator, chip_generator_dict, batchsize=1000):\n",
    "    targets = []\n",
    "    inputs = []\n",
    "    for element in range(batchsize):\n",
    "        mat = next(hic_generator)\n",
    "        targets.append(mat)\n",
    "        signal_list = list()\n",
    "        for k, (key, chip_generator) in enumerate(chip_generator_dict.items()):\n",
    "            signal_list.append(next(chip_generator))\n",
    "            \n",
    "        inputs.append(np.array(signal_list).T)\n",
    "    \n",
    "    return np.array(inputs), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6f0296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3K27ac\n",
      "H3K27me3\n",
      "H3K9me3\n"
     ]
    }
   ],
   "source": [
    "hic_generator = regionsLoader.hic_loader(train_regions_df, cool_path, resolution=50000)\n",
    "chip_generator_dict = {}\n",
    "\n",
    "for key, path in bigwig_dict.items():\n",
    "    print(key)\n",
    "    chip_generator_dict[key] = regionsLoader.chip_loader(train_regions_df, path, resolution=10000)\n",
    "\n",
    "train_inputs, train_targets = build_set(hic_generator, chip_generator_dict, batchsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcf908c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(train_targets[0, :80-2,:80-2], 1, mode='edge').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e8103b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3K27ac\n",
      "H3K27me3\n",
      "H3K9me3\n"
     ]
    }
   ],
   "source": [
    "hic_generator = regionsLoader.hic_loader(test_regions_df, cool_path, resolution=50000)\n",
    "chip_generator_dict = {}\n",
    "\n",
    "for key, path in bigwig_dict.items():\n",
    "    print(key)\n",
    "    chip_generator_dict[key] = regionsLoader.chip_loader(test_regions_df, path, resolution=10000)\n",
    "\n",
    "test_inputs, test_targets = build_set(hic_generator, chip_generator_dict, batchsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "923b3d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 80, 80)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efb6107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0e00cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def flat_to_mat_TF(vector, n=N):\n",
    "    idx = list(zip(*np.triu_indices(n)))\n",
    "    idx = tf.constant([list(i) for i in idx], dtype=tf.int64)\n",
    "    sp_input = tf.SparseTensor(indices = idx, values = vector, dense_shape=(n,n))\n",
    "        \n",
    "    mat = tf.sparse.to_dense(sp_input, default_value=0)\n",
    "    mat = mat + K.transpose(mat)\n",
    "    \n",
    "    mat = tf.linalg.set_diag(mat, tf.linalg.diag_part(mat)/2)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2866c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(0, N)[:, None]\n",
    "distance = np.abs(idx-idx.T)+0.1\n",
    "iu = np.triu_indices(N)\n",
    "distance_iu = distance[iu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c40007a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_input, N):\n",
    "    \n",
    "    x = keras.layers.Conv1D(name='Conv1a', filters = 32, kernel_size= 5, dilation_rate=2, \n",
    "                            padding='same', activation='relu')(model_input)\n",
    "    x = keras.layers.Conv1D(name='Conv1b', filters = 32, kernel_size= 5, dilation_rate=2, \n",
    "                            padding='same', activation='relu')(x)\n",
    "    x = keras.layers.MaxPool1D(name='Pool1', pool_size=2)(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = keras.layers.Conv1D(name='Conv2a', filters = 64, kernel_size= 5, dilation_rate=4,\n",
    "                            padding='same', activation='relu')(x)\n",
    "    x = keras.layers.Conv1D(name='Conv2b', filters = 64, kernel_size= 5, dilation_rate=4,\n",
    "                            padding='same', activation='relu')(x)\n",
    "    x = keras.layers.MaxPool1D(name='Pool2', pool_size=2)(x)\n",
    "    \n",
    "    \n",
    "    x = keras.layers.Conv1D(name='Conv3a', filters = 64, kernel_size= 5, dilation_rate=2,\n",
    "                        padding='valid', activation='relu')(x)\n",
    "    x = keras.layers.Conv1D(name='Conv3b', filters = 64, kernel_size= 5, dilation_rate=2,\n",
    "                        padding='valid', activation='relu')(x)\n",
    "    \n",
    "    \n",
    "    x = keras.layers.Conv1D(name='Conv3c', filters = 128, kernel_size= 3, dilation_rate=2,\n",
    "                    padding='valid', activation='relu')(x)\n",
    "    \n",
    "    \n",
    "    x = keras.layers.Conv1D(name='Conv3d', filters = 64, kernel_size= 3,\n",
    "                padding='same', activation='linear')(x)\n",
    "    \n",
    "    \n",
    "    x = keras.layers.Lambda(lambda x: K.expand_dims(x, axis=1), name='expand_dims')(x)\n",
    "    xt = keras.layers.Permute( (2, 1, 3), name='permute_0')(x)\n",
    "    x = keras.layers.Add(name='add_0')([x, xt])\n",
    "    \n",
    "\n",
    "    x_in = x\n",
    "    x = keras.layers.Conv2D(64, 3, activation='relu', padding='same',name='Conv2Da')(x)\n",
    "    x = keras.layers.Conv2D(128, 1, activation='relu', padding='same',name='Conv2Db')(x)\n",
    "    x = keras.layers.Conv2D(64, 3, activation='linear', padding='same', name='Conv2Dc')(x)\n",
    "    xt = keras.layers.Permute( (2, 1, 3), name='permute')(x)\n",
    "    x = keras.layers.Add(name='add')([x, xt, x_in])\n",
    "    \n",
    "    \n",
    "    x_in = x\n",
    "    x = keras.layers.Conv2D(64, 3, activation='relu', padding='same',name='Conv2Da_2')(x)\n",
    "    x = keras.layers.Conv2D(128, 1, activation='relu', padding='same',name='Conv2Db_2')(x)\n",
    "    x = keras.layers.Conv2D(64, 3, activation='linear', padding='same', name='Conv2Dc_2')(x)\n",
    "    xt = keras.layers.Permute( (2, 1, 3), name='permute_2')(x)\n",
    "    x = keras.layers.Add(name='add_2')([x, xt, x_in])\n",
    "    \n",
    "    \n",
    "    x_in = x\n",
    "    x = keras.layers.Conv2D(64, 3, activation='relu', padding='same',name='Conv2Da_3')(x)\n",
    "    x = keras.layers.Conv2D(128, 1, activation='relu', padding='same',name='Conv2Db_3')(x)\n",
    "    x = keras.layers.Conv2D(64, 3, activation='linear', padding='same', name='Conv2Dc_3')(x)\n",
    "    xt = keras.layers.Permute( (2, 1, 3), name='permute_3')(x)\n",
    "    x = keras.layers.Add(name='add_3')([x, xt, x_in])\n",
    "    \n",
    "    \n",
    "#     x = keras.layers.Dense(256, activation='relu',name='Dense_semifinal1')(x)\n",
    "#     x = keras.layers.Dense(512, activation='relu',name='Dense_semifinal2')(x)\n",
    "\n",
    "    x = keras.layers.Dense(1, name='Dense_final')(x)\n",
    "    \n",
    "    x = regionsLoader.layers.UpperTri(diagonal_offset=0)(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    x = keras.layers.Flatten(name='Flatten')(x)\n",
    "#     x = keras.layers.Dense(512, activation='relu', name='Dense_1')(x)\n",
    "#     x = keras.layers.Dense(((N*N)//2) + (N//2), name='Dense_final')(x)\n",
    "#                            kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4))(x)\n",
    "#                            bias_regularizer=keras.regularizers.l2(1e-4))(x),\n",
    "#     x = keras.layers.Reshape((80,80), name='Reshaper')(x)\n",
    "    x = keras.backend.exp(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f591475",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def custom_loss(y_actual,y_pred):\n",
    "#     print('y_actual.shape', y_actual.shape)\n",
    "#     y_pred = tf.map_fn(flat_to_mat_TF, y_pred)\n",
    "    y_actual = K.log(y_actual+1e-10)\n",
    "    y_pred = K.log(y_pred+1e-10)\n",
    "    loss_square = K.square(y_actual-y_pred)*distance_iu\n",
    "    \n",
    "    custom_loss = tf.reduce_sum(loss_square, axis=-1)\n",
    "    custom_loss = tf.reduce_mean(custom_loss, axis=-1)\n",
    "    \n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d746d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 14:29:07.021169: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-05 14:29:07.021475: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-05 14:29:07.104507: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method UpperTri.call of <regionsLoader.layers.UpperTri object at 0x7f5aba0734d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method UpperTri.call of <regionsLoader.layers.UpperTri object at 0x7f5aba0734d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model_input = keras.Input(shape=(400, 3, ), name='model_input')\n",
    "model = keras.Model(inputs=model_input, outputs=create_model(model_input, N), name='model_1')\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=custom_loss, run_eagerly=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd432f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "model_input (InputLayer)        [(None, 400, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1a (Conv1D)                 (None, 400, 32)      512         model_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv1b (Conv1D)                 (None, 400, 32)      5152        Conv1a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Pool1 (MaxPooling1D)            (None, 200, 32)      0           Conv1b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv2a (Conv1D)                 (None, 200, 64)      10304       Pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv2b (Conv1D)                 (None, 200, 64)      20544       Conv2a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Pool2 (MaxPooling1D)            (None, 100, 64)      0           Conv2b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv3a (Conv1D)                 (None, 92, 64)       20544       Pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv3b (Conv1D)                 (None, 84, 64)       20544       Conv3a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv3c (Conv1D)                 (None, 80, 128)      24704       Conv3b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv3d (Conv1D)                 (None, 80, 64)       24640       Conv3c[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "expand_dims (Lambda)            (None, 1, 80, 64)    0           Conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_0 (Permute)             (None, 80, 1, 64)    0           expand_dims[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_0 (Add)                     (None, 80, 80, 64)   0           expand_dims[0][0]                \n",
      "                                                                 permute_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Da (Conv2D)                (None, 80, 80, 64)   36928       add_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Db (Conv2D)                (None, 80, 80, 128)  8320        Conv2Da[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Dc (Conv2D)                (None, 80, 80, 64)   73792       Conv2Db[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 80, 80, 64)   0           Conv2Dc[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 80, 80, 64)   0           Conv2Dc[0][0]                    \n",
      "                                                                 permute[0][0]                    \n",
      "                                                                 add_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Da_2 (Conv2D)              (None, 80, 80, 64)   36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Db_2 (Conv2D)              (None, 80, 80, 128)  8320        Conv2Da_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Dc_2 (Conv2D)              (None, 80, 80, 64)   73792       Conv2Db_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 80, 80, 64)   0           Conv2Dc_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 80, 80, 64)   0           Conv2Dc_2[0][0]                  \n",
      "                                                                 permute_2[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Da_3 (Conv2D)              (None, 80, 80, 64)   36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Db_3 (Conv2D)              (None, 80, 80, 128)  8320        Conv2Da_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv2Dc_3 (Conv2D)              (None, 80, 80, 64)   73792       Conv2Db_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 80, 80, 64)   0           Conv2Dc_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 80, 80, 64)   0           Conv2Dc_3[0][0]                  \n",
      "                                                                 permute_3[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dense_final (Dense)             (None, 80, 80, 1)    65          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "upper_tri (UpperTri)            (None, 3240, 1)      0           Dense_final[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Flatten (Flatten)               (None, 3240)         0           upper_tri[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 3240)         0           Flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 484,129\n",
      "Trainable params: 484,129\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d9d4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.set_value(model.optimizer.learning_rate, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bd42643",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_regions_df = train_regions_df.sample(frac=1, random_state=99).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82747595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr4</td>\n",
       "      <td>44303750</td>\n",
       "      <td>48303750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2</td>\n",
       "      <td>188313750</td>\n",
       "      <td>192313750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2</td>\n",
       "      <td>35991250</td>\n",
       "      <td>39991250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2</td>\n",
       "      <td>168665000</td>\n",
       "      <td>172665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2</td>\n",
       "      <td>114400000</td>\n",
       "      <td>118400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47283</th>\n",
       "      <td>chr4</td>\n",
       "      <td>70575000</td>\n",
       "      <td>74575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47284</th>\n",
       "      <td>chr4</td>\n",
       "      <td>149535000</td>\n",
       "      <td>153535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47285</th>\n",
       "      <td>chr4</td>\n",
       "      <td>21950000</td>\n",
       "      <td>25950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47286</th>\n",
       "      <td>chr3</td>\n",
       "      <td>30267500</td>\n",
       "      <td>34267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47287</th>\n",
       "      <td>chr3</td>\n",
       "      <td>171631250</td>\n",
       "      <td>175631250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47288 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chrom      start        end\n",
       "0      chr4   44303750   48303750\n",
       "1      chr2  188313750  192313750\n",
       "2      chr2   35991250   39991250\n",
       "3      chr2  168665000  172665000\n",
       "4      chr2  114400000  118400000\n",
       "...     ...        ...        ...\n",
       "47283  chr4   70575000   74575000\n",
       "47284  chr4  149535000  153535000\n",
       "47285  chr4   21950000   25950000\n",
       "47286  chr3   30267500   34267500\n",
       "47287  chr3  171631250  175631250\n",
       "\n",
       "[47288 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_regions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56cffb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(regionsLoader)\n",
    "reload(regionsLoader.layers)\n",
    "reload(regionsLoader.generator)\n",
    "chip_names =['H3K27ac', 'H3K27me3', 'H3K9me3']\n",
    "train_generator = regionsLoader.generator.DataGenerator(train_regions_df, chip_names, \n",
    "                            cool_path=cool_path, chip_path_dict = bigwig_dict, \n",
    "                            cool_resolution=50000, chip_resolution=10000, batch_size=16)\n",
    "\n",
    "test_generator = regionsLoader.generator.DataGenerator(test_regions_df, chip_names, \n",
    "                            cool_path=cool_path, chip_path_dict = bigwig_dict, \n",
    "                            cool_resolution=50000, chip_resolution=10000, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc02808d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method UpperTri.call of <regionsLoader.layers.UpperTri object at 0x7f5aba264950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method UpperTri.call of <regionsLoader.layers.UpperTri object at 0x7f5aba264950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.load_model('conv_model2.h5', \n",
    "                              custom_objects={'UpperTri': regionsLoader.layers.UpperTri,\n",
    "                                             'custom_loss': custom_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26f80ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.learning_rate, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115ea21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 14:29:09.500625: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-05 14:29:09.503918: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2095050000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 858/2955 [=======>......................] - ETA: 1:11:46 - loss: 17458.3066"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0adcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('conv_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a204498",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_inputs)\n",
    "train_predictions = model.predict(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(targets, predictions):\n",
    "    fig = plt.figure(figsize= (16, 16))\n",
    "    for i in range(8):\n",
    "        ax = plt.subplot(4,4, (i*2)+1)\n",
    "        ax.matshow(np.log(targets[i]+5e-6), cmap='YlOrRd')\n",
    "        ax.set_title('target')\n",
    "        ax = plt.subplot(4,4, (i*2)+2)\n",
    "        ax.set_title('prediction')\n",
    "        ax.matshow(np.log(regionsLoader.from_upper_triu(predictions[i], N)+5e-6), cmap='YlOrRd', \n",
    "                   vmax=np.nanmax(np.log(targets[i]+5e-6)), \n",
    "                   vmin=np.nanmin(np.log(targets[i]+5e-6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a930c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(train_targets, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(test_targets, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes = bf.fetch_chromsizes('hg38').iloc[11:12]\n",
    "region_chrom = bf.binnify(chromsizes, binsize=4000000)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4307a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "hic_generator = regionsLoader.hic_loader(region_chrom, cool_path, resolution=50000)\n",
    "chip_generator_dict = {}\n",
    "\n",
    "for key, path in bigwig_dict.items():\n",
    "    print(key)\n",
    "    chip_generator_dict[key] = regionsLoader.chip_loader(region_chrom, path, resolution=10000)\n",
    "\n",
    "test_inputs2, test_targets2 = build_set(hic_generator, chip_generator_dict, batchsize=len(region_chrom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbeb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions2 = model.predict(test_inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ea4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3370ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(test_targets2, test_predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8df4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_regions_df = bf.select(all_regions_df, 'chr19').sample(frac=1, random_state=28) #select a chromosome and shuffle it\n",
    "# hic_generator = hic_loader(target_regions_df, cool_path, resolution=50000)\n",
    "# chip_generator_dict = {}\n",
    "# for key, value in bigwig_dict.items():\n",
    "#     chip_generator_dict[key] = chip_loader(target_regions_df, value, resolution=10000)\n",
    "\n",
    "# test_inputs2, test_targets2 = build_set(hic_generator, chip_generator_dict, batchsize=4)\n",
    "# test_predictions2 = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a10c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize= (16, 16))\n",
    "# for i in range(4):\n",
    "#     ax = plt.subplot(4,4, (i*2)+1)\n",
    "#     ax.matshow(np.log(test_targets2[i]+5e-6), cmap='YlOrRd')\n",
    "#     ax.set_title('target')\n",
    "#     ax = plt.subplot(4,4, (i*2)+2)\n",
    "#     ax.set_title('prediction')\n",
    "#     ax.matshow(test_predictions2[i], cmap='YlOrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_mat = np.exp(model.predict(inputs[0:1])[0])-5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7205063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.log(targets[0]+5e-6), cmap='YlOrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e72d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.log(pred_mat+5e-6), cmap='YlOrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1 = np.array([np.diag(targets[0], i).mean() for i in range(80)])\n",
    "# P2 = np.array([np.diag(pred_mat, i).mean() for i in range(80)])\n",
    "# x = np.arange(0, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.log(x[1:]), np.log(P1[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58846f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.log(x[1:]), np.log(P2[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618fbe6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
